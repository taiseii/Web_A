{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 80B8-8562\n",
      "\n",
      " Directory of C:\\Users\\taiseii\\OneDrive - TU Eindhoven\\Documents\\WebA\\a3\n",
      "\n",
      "06-Jan-19  22:18    <DIR>          .\n",
      "06-Jan-19  22:18    <DIR>          ..\n",
      "06-Jan-19  18:01    <DIR>          .ipynb_checkpoints\n",
      "03-Jan-19  14:01           130,291 e3-EMM.pdf\n",
      "06-Jan-19  18:17         6,145,079 HW3 - Copy.ipynb\n",
      "06-Jan-19  22:18         6,146,853 HW3.ipynb\n",
      "03-Jan-19  13:55           638,020 HW3instructions.pdf\n",
      "04-Jan-19  17:52         2,893,465 J5-EMM_DMKD.pdf\n",
      "03-Jan-19  15:49       132,546,563 Web_Anlaytics_Nov_2018_final.csv\n",
      "04-Jan-19  15:15         1,753,030 week3B-SD.pdf\n",
      "04-Jan-19  14:04         4,516,827 week4A_EMM.pdf\n",
      "04-Jan-19  17:39        23,047,315 week4B_EMM2.pdf\n",
      "04-Jan-19  17:39         2,125,837 week4C_SP.pdf\n",
      "              10 File(s)    179,943,280 bytes\n",
      "               3 Dir(s)  887,362,396,160 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq as hp\n",
    "from collections import deque\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # also improves the look of plots\n",
    "import random\n",
    "import queue\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Web_Anlaytics_Nov_2018_final.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>a)</h2> <h4>targets = Combination id : Converted :</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344785, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.tail()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Screen Resolution',\n",
       " 'Browser',\n",
       " 'Browser Version',\n",
       " 'Device Type',\n",
       " 'Device',\n",
       " 'OS',\n",
       " 'OS Version',\n",
       " 'User Agent',\n",
       " 'Traffic Source',\n",
       " 'Combination Id',\n",
       " 'Converted',\n",
       " 'Conversion Time',\n",
       " 'Returning Visitor',\n",
       " 'Hit Time',\n",
       " 'User Language',\n",
       " 'URL',\n",
       " 'Referring URL',\n",
       " 'City',\n",
       " 'Region',\n",
       " 'Country',\n",
       " 'Goal 1 Converted',\n",
       " 'Goal 1 Converted Time']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1938,)\n",
      "(45,)\n",
      "(834,)\n",
      "(4,)\n",
      "(4302,)\n",
      "(27,)\n",
      "(173,)\n",
      "(22336,)\n",
      "(5,)\n",
      "(2,)\n",
      "(2,)\n",
      "(4456,)\n",
      "(2,)\n",
      "(255253,)\n",
      "(279,)\n",
      "(42758,)\n",
      "(20392,)\n",
      "(15636,)\n",
      "(2007,)\n",
      "(228,)\n",
      "(3,)\n",
      "(4373,)\n"
     ]
    }
   ],
   "source": [
    "for x in list(df):\n",
    "    header = str(x)\n",
    "    print(df[header].unique().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Converted'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    88,    206,    282,    323,    397,    574,    604,    645,\n",
       "               690,    810,\n",
       "            ...\n",
       "            343074, 343185, 343468, 343500, 343524, 343851, 344052, 344064,\n",
       "            344485, 344521],\n",
       "           dtype='int64', length=4470)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Conversion Time'].dropna().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>b)</h2><h4>assumption 1 : Data is generated by human</h4><h4>assumption 2 : Human produced this data was in similar state of mind(not under extreme stress/pressure etc)</h4> <h4>assumption 3 : There is no statistical bias(this sample represent the population)</h4> <h4>assumption 4 : website assigned is random</h4> \n",
    "<h4>assumption 5 : Hit time = when the page has landed for the first time</h4>\n",
    "<h4>descriptor 1 : everything excluding targets. Some of the attribute might seem useless at first but might contribute in identifying the relevant subgroup later.</h4> \n",
    "<h4>descriptor 2 : \"conversion rate for 1 or 2(new variable)\"(when later subgrouping people)=(total conversion=true for of 1 or 2)/(total number of 1 or 2 shown). This is a good indicator to see proportion of success</h4>\n",
    "<h4>descriptor 3 : time to conversion = Hit time - conversion time, if assumption 5 is true then this can be a measurement of how fast the customer has clicked the website which can be a indicator how good the conversion is.</h4>\n",
    "<h4>preprocessing 0 : df = pd.read_csv(\"Web_Anlaytics_Nov_2018_final.csv\",encoding = \"ISO-8859-1\") after separating columns using excel. This create one table with both targets and descriptors. We will not separate data at this point since this will be taken care by beam search</h4>\n",
    "<h4>preprocessing 1 : Goal 1 Converted Time = Conversion Time</h4>\n",
    "<h4>preprocessing 2 : Create descriptor 3</4>\n",
    "<h4>preprocessing 3 : Converesion of dataframe to numpy array</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-22T08:47:39\n",
      "nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 3, 22, 13, 47, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Hit Time']-df['Conversion Time']\n",
    "type(df['Hit Time'][0])\n",
    "type(df['Conversion Time'][0])\n",
    "print(df['Hit Time'][0])\n",
    "print(df['Conversion Time'][0])\n",
    "import time\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "# print(dateutil.parser.parser(df['Hit Time'][0]))\n",
    "datetime.datetime.strptime(df['Hit Time'][0], \"%Y-%m-%dT%H:%M:%S\")\n",
    "datetime.datetime.strptime(str(df['Conversion Time'][88]), \"%Y-%m-%dT%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['Browser'] = df['Browser'].astype('category') \n",
    "df2['Device Type'] = df['Device Type'].astype('category')\n",
    "df2['Device'] = df['Device'].astype('category')\n",
    "df2['OS'] = df['OS'].astype('category')\n",
    "# df2['User Agent']=df['User Agent'].astype('category')\n",
    "df2['Returning Visitor']=df['Returning Visitor'].astype('category')\n",
    "df2['User Language']=df['User Language'].astype('category')\n",
    "df2['Country']=df['Country'].astype('category')\n",
    "df2['X']=df['Combination Id'].astype('category')\n",
    "df2['Y']=df['Converted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user agent info = device type .... \n",
    "import re\n",
    "regex = re.compile(r'[^\\s]+')\n",
    "re.search(regex, df['Device'][0]).group(0)\n",
    "\n",
    "devices = deque()\n",
    "for x in range(len(df2['Device'])):\n",
    "#     print(re.search(regex, df2['Device'][x]).group(0))\n",
    "    devices.append(re.search(regex, df2['Device'][x]).group(0))\n",
    "    \n",
    "df2['Device 2'] = devices\n",
    "# devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_np = np.asarray(list(zip(df2['Browser'],\n",
    "                            df2['Device Type'],\n",
    "                            df2['Device'],\n",
    "                            df2['OS'],\n",
    "                            df2['User Agent'],\n",
    "                            df2['Returning Visitor'],\n",
    "                            df2['User Language'],\n",
    "                            df2['Country'],\n",
    "                            df2['X'],\n",
    "                            df2['Y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_np_descriptors = np.asarray(list(zip(df2['Browser'],\n",
    "                            df2['Device Type'],\n",
    "                            df2['Device'],\n",
    "                            df2['OS'],\n",
    "                            df2['User Agent'],\n",
    "                            df2['Returning Visitor'],\n",
    "                            df2['User Language'],\n",
    "                            df2['Country'])))\n",
    "df2_np_targets = np.asarray(list(zip(df2['X'],\n",
    "                            df2['Y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maximum d\n",
    "len(df2_np_descriptors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Q2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>a)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pysubgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2_np.shape)\n",
    "sequence = [[list(),1.0]]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def qualityM(n1,n2,n3,n4):\n",
    "#     if (n1*n4 + n2*n3) == 0 :\n",
    "#         yule = 0\n",
    "#     else :\n",
    "#         yule = (n1*n4 - n2*n3)/(n1*n4 + n2*n3)\n",
    "#     return yule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df must be a subset(only the solution) of the DataFrame which meatches the descriptor \n",
    "def YQ(df):\n",
    "    if df.shape != (2,2):\n",
    "        return 0\n",
    "    else:\n",
    "        n1 = df[0][0]\n",
    "        n2 = df[1][0]\n",
    "        n3 = df[0][1]\n",
    "        n4 = df[1][1]\n",
    "        return ((n1*n4) - (n2*n3))/((n1*n4) + (n2*n3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RefinementO(seed, df, possibleValues):\n",
    "    result = []\n",
    "    for attribute in df.columns.drop(['X','Y']):\n",
    "        checked = False\n",
    "        for condition in seed:\n",
    "            if attribute == condition[0]:\n",
    "                checked = True\n",
    "                break\n",
    "        if not checked:\n",
    "            attribute_str = str(attribute)\n",
    "            if len(df[attribute_str].unique()) == 2 : #binary\n",
    "                result.append(seed + [(attribute, '=',\n",
    "                                       possibleValues[attribute][0])])\n",
    "                result.append(seed + [(attribute, '=',\n",
    "                                       possibleValues[attribute][1])])\n",
    "            else: \n",
    "                for value in possibleValues[attribute]: #non binary\n",
    "                    result.append(seed + [(attribute, '=', value)])\n",
    "                    result.append(seed + [(attribute, '!=', value)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.drop(['X','Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PossibleValues(dataframe):\n",
    "     result = {}\n",
    "     for attribute in dataframe.columns:\n",
    "         result[attribute] = set()\n",
    "         for value in dataframe[attribute]:\n",
    "             result[attribute].add(value)\n",
    "     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PossibleValues(df2.drop(['X','Y'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsizeOK(descriptor, min_size, dataframe=df):\n",
    "    descriptor_slice = dataframe\n",
    "    for condition in descriptor:\n",
    "        descriptor_slice = descriptor_slice[ops[condition[1]](descriptor_slice[condition[0]], \n",
    "                                                              condition[2])]\n",
    "    if descriptor_slice.shape[0] > min_size:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSearch(df, w, d, qualityM = YQ):\n",
    "    counter = 0\n",
    "    candidate = deque()\n",
    "    candidate.append([])\n",
    "    resultSet =[]\n",
    "    possible_descriptors = PossibleValues( df.drop(['X','Y'], axis=1) )\n",
    "    \n",
    "    for level in range(d):\n",
    "        beam = []\n",
    "        while candidate:\n",
    "            seeds = candidate.pop()\n",
    "            \n",
    "            if len(seeds)>0:\n",
    "                seed = seeds[2]\n",
    "            else:\n",
    "                seed = seeds\n",
    "            candidateDescriptors = RefinementO(seed, df, possible_descriptors)\n",
    "            for drs in candidateDescriptors:\n",
    "                drs_slice = df\n",
    "                for condition in descriptor:\n",
    "                    drs_slice = drs_slice[ops[condition[1]]\n",
    "                                          (descriptor_slice[condition[0]],condition[2])]\n",
    "                quality = abs((qualityM(drs_slice)))\n",
    "                if quality == 1.0:\n",
    "                    continue\n",
    "                if minsizeOK(descriptor, min_size):\n",
    "                    if len(result_set) == q:\n",
    "                        heapq.heappushpop(result_set, (quality, count, descriptor))\n",
    "                    else:\n",
    "                         heapq.heappush(result_set, (quality, count,descriptor))\n",
    "                    if len(beam) == w:\n",
    "                        heapq.heappushpop(beam, (quality, count, descriptor))\n",
    "                    else:\n",
    "                        heapq.heappush(beam, (quality, count, descriptor))\n",
    "                    counter += 1\n",
    "        while (beam):\n",
    "            candidate.append(hp.heappop(beam))\n",
    "    print(resultSet)\n",
    "    return 1\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSearch(df2, 2, 3, qualityM = YQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def beamSearch(descriptors,targets, w, d):\n",
    "#     candidate = []\n",
    "#     resultSet = []\n",
    "    \n",
    "#     for i in range(d):\n",
    "#         beam = []\n",
    "#         beam = [0]*w\n",
    "        \n",
    "#         while len(candidate)>0 :\n",
    "#             print(i)\n",
    "#             descriptor_step = []\n",
    "#             for dr in range(descriptors.shape[0]):\n",
    "#                 descriptor_step.append(descriptors[dr][i-1])\n",
    "#             descriptor_step_df = pd.DataFrame(descriptor_step)\n",
    "#             print(descriptor_step_df[0].unique())\n",
    "#             targets_df = pd.DataFrame(targets)\n",
    "            \n",
    "#             score_d = []\n",
    "#             for uq in descriptor_step_df[0].unique():\n",
    "#                 n1 = 0\n",
    "#                 n2 = 0\n",
    "#                 n3 = 0\n",
    "#                 n4 = 0\n",
    "#                 subgroup = []\n",
    "#                 subgroup = descriptor_step_df.index[descriptor_step_df[0] == uq].tolist()\n",
    "#                 for index in range(len(subgroup)):\n",
    "#                     X = targets_df.loc[subgroup[index],0]\n",
    "#                     Y = targets_df.loc[subgroup[index],1]\n",
    "#                     if (X== '1') and (Y=='No'):\n",
    "#                         n1 += 1\n",
    "#                     elif (X=='1') and (Y=='Yes'):\n",
    "#                         n2 += 1\n",
    "#                     elif (X=='2') and (Y=='No'):\n",
    "#                         n3 += 1\n",
    "#                     elif (X=='2') and (Y=='Yes'):\n",
    "#                         n4 += 1\n",
    "#                 hp.heappush(score_d, (qualityM(n1,n2,n3,n4), uq))\n",
    "#             print(hp.nsmallest(5, score_d))\n",
    "#             print(hp.nlargest(5, score_d))\n",
    "            \n",
    "# #             seed = candidate.pop(0)\n",
    "# #             seets = {seed}\n",
    "            \n",
    "#             hp.heappush(resultSet, (hp.nlargest(1, score_d)))\n",
    "#             hp.heappush(beam, (hp.nlargest(1, score_d)))\n",
    "#             for element in seets:\n",
    "                \n",
    "#                 quality = qualityM(n1,n2,n3,n4)\n",
    "                \n",
    "#                 hp.heappush(resultSet, (quality, element))\n",
    "#                 hp.heappush(beam, (quality, element))\n",
    "#         while len(beam)>0:\n",
    "#             candidate.append(beam.pop())\n",
    "#     return resultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamSearch(df2_np_descriptors,df2_np_targets,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = deque()\n",
    "# x.append([])\n",
    "x\n",
    "len(x)\n",
    "if(x):\n",
    "    print ('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>w is number of descroptions within the d(level), seed is higher level than candidate. It's going to be inside the beam</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_np_targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimentation zone 2\n",
    "h = []\n",
    "hp.heappush(h, (5, 'write code'))\n",
    "hp.heappush(h, (7, 'write code'))\n",
    "hp.heappush(h, (6, 'write code'))\n",
    "hp.heappush(h, (8, 'write code'))\n",
    "hp.heappush(h, (4, 'write code'))\n",
    "hp.heappush(h, (7, 'write code'))\n",
    "hp.heappush(h, (6, 'write code'))\n",
    "hp.heappush(h, (2, 'write code'))\n",
    "hp.heappop(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
